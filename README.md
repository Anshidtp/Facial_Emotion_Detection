#  üé≠ Facial_Emotion_Detection


This project uses **MediaPipe Face Mesh** with **OpenCV** to detect and visualize **facial landmarks** in real time.  
Instead of just using a webcam, this implementation also supports **YouTube video input** 

---

## ‚ú® Features
- Real-time **Face Mesh detection** with over 468 facial landmarks  
- **Contours & iris tracking** for refined visualization  
- Works with **webcam** or **YouTube video links**  
- On-screen instructions for user interaction  

---

## üìπ Demo
Check out the demo video here:  

[![Demo Video](https://github.com/Anshidtp/Facial_Emotion_Detection/blob/main/sample_demo/facial_landmarks.gif)]

---

## ‚öôÔ∏è Installation

1. Clone repository

    ```bash
    git clone https://github.com/Anshidtp/Facial_Emotion_Detection.git
    cd Facial_Emotion_Detection
    ```

2. Create and activate virtual environment

    ```bash
    python -m venv venv
    source venv/bin/activate  # Windows: venv\Scripts\activate

    ```

3. Install dependencies

    ```bash
    pip install -r requirements.txt

    ```

    ```
4. Run the backend server
    ```bash 
    python face_landmarks_detect.py
    ```
